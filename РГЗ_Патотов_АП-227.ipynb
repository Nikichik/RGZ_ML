{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Liveness Detection (Anti-Spoofing) — вариант 57\n",
        "\n",
        "## Анализ предметной области и постановка задачи\n",
        "\n",
        "Современные системы биометрической аутентификации уязвимы к атакам подмены личности\n",
        "(presentation attacks), при которых злоумышленник использует фотографию, видеозапись\n",
        "или экран для обмана системы распознавания лиц. В связи с этим актуальной является задача\n",
        "**детекции живости лица (liveness detection)** — определения, принадлежит ли изображение\n",
        "реальному человеку или является спуфинг-атакой.\n",
        "\n",
        "**Цель работы:** разработка и экспериментальная проверка программного прототипа\n",
        "детекции живости лица на основе анализа текстурных признаков изображения.\n",
        "\n",
        "**Задачи:**\n",
        "- проанализировать методы детекции живости;\n",
        "- реализовать алгоритм извлечения признаков;\n",
        "- обучить классификатор;\n",
        "- оценить эффективность метода;\n",
        "- сформулировать выводы о применимости технологии.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Обзор существующих методов детекции живости\n",
        "\n",
        "Существующие подходы к liveness detection можно условно разделить на несколько групп:\n",
        "\n",
        "1. **Анализ движений и поведения** (моргание, микродвижения, реакция на команды).\n",
        "2. **Текстурный анализ** — выявление отличий текстуры кожи от печатных или экранных изображений.\n",
        "3. **Глубинные методы** — использование нейронных сетей (CNN, Transformer).\n",
        "4. **Мультимодальные подходы** — объединение RGB, depth, IR.\n",
        "\n",
        "В рамках учебной работы выбран **текстурный метод на основе LBP**,\n",
        "как интерпретируемый и вычислительно простой.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Описание реализации выбранного алгоритма\n",
        "\n",
        "### Используемые данные\n",
        "\n",
        "Датасет содержит изображения лиц, разделённые на обучающую (`train_img`) и тестовую (`test_img`) выборки.\n",
        "Класс изображения определяется по имени файла:\n",
        "- `_real` — живое лицо (label = 1);\n",
        "- `_fake` — спуфинг-атака (label = 0).\n",
        "\n",
        "### Признаки\n",
        "Для извлечения признаков используется **Local Binary Patterns (LBP)** —\n",
        "метод анализа локальной текстуры изображения.\n",
        "\n",
        "### Классификатор\n",
        "В качестве классификатора используется **логистическая регрессия**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорты\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay, ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "def load_images(path, max_per_class=150):\n",
        "    X, y = [], []\n",
        "    files = [f for f in os.listdir(path) if f.endswith('.jpg')]\n",
        "    real = [f for f in files if '_real' in f][:max_per_class]\n",
        "    fake = [f for f in files if '_fake' in f][:max_per_class]\n",
        "\n",
        "    for fname in real + fake:\n",
        "        img = cv2.imread(os.path.join(path, fname), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, IMG_SIZE)\n",
        "        label = 1 if '_real' in fname else 0\n",
        "        X.append(img)\n",
        "        y.append(label)\n",
        "    return np.array(X), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lbp_histogram(gray):\n",
        "    h, w = gray.shape\n",
        "    lbp = np.zeros_like(gray)\n",
        "    offsets = [(-1,-1), (-1,0), (-1,1), (0,1), (1,1), (1,0), (1,-1), (0,-1)]\n",
        "    for y in range(1, h-1):\n",
        "        for x in range(1, w-1):\n",
        "            center = gray[y, x]\n",
        "            code = 0\n",
        "            for i, (dy, dx) in enumerate(offsets):\n",
        "                code |= (gray[y+dy, x+dx] >= center) << i\n",
        "            lbp[y, x] = code\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=256, range=(0,256), density=True)\n",
        "    return hist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Экспериментальные исследования\n",
        "\n",
        "Обучение выполняется на `train_img`, оценка — на независимой тестовой выборке `test_img`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_img, y_train = load_images('dataset/train_img/color')\n",
        "X_test_img, y_test = load_images('dataset/test_img/color')\n",
        "\n",
        "X_train = np.array([lbp_histogram(img) for img in X_train_img])\n",
        "X_test = np.array([lbp_histogram(img) for img in X_test_img])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('ROC-AUC:', roc_auc_score(y_test, y_proba))\n",
        "\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
        "plt.show()\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    display_labels=[\"spoof\", \"live\"],\n",
        "    cmap=\"Blues\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Выводы и рекомендации по применению\n",
        "\n",
        "В ходе работы был разработан программный прототип детекции живости лица\n",
        "на основе текстурных признаков LBP и логистической регрессии.\n",
        "\n",
        "**Выводы:**\n",
        "- метод демонстрирует способность различать живые лица и спуфинг-атаки;\n",
        "- использование независимой тестовой выборки обеспечивает объективную оценку качества;\n",
        "- алгоритм обладает низкой вычислительной сложностью.\n",
        "\n",
        "**Ограничения:**\n",
        "- чувствительность к освещению;\n",
        "- ограниченная устойчивость к сложным атакам.\n",
        "\n",
        "**Рекомендации:**\n",
        "- использовать в учебных и прототипных системах;\n",
        "- для практического применения комбинировать с глубинными моделями и мультимодальными данными.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv310 (3.10.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
